---
layout:     post
title:      初入Hadoop生态系统
subtitle:   高可用设计
date:       2018-07-28
author:     ohcomeyes
header-img: img/post-blog3.jpg
catalog: true
tags:
    - Java
    - Hadoop
---
### 前言
说起Hadoop，知道它是一个开源的、可运行于大规模集群上的分布式计算平台，实现了MapReduce计算模型和分布式文件系统HDFS等功能；但对Hadoop整个的生态不够了解，本着爱学习的态度，一块来探探hadoop的生态圈。

### 关于Hadoop
日常生活中我们一看到大数据和大数据相关的信息就会想到了hadoop，但要说具体点，又不知从何说起。
hadoop是基于Java开发的，所以在跨平台上有很大的优势，并且可以部署在廉价的计算机集群中，所以导致hadoop的火热程度。hadoop的核心是HDFS和MapReduce，HDFS是针对谷歌文件系统(GFS)的开源实现，具有较高的读写速度、容错性、可伸缩性，采用MapReduce的整合，可以在不了解分布式系统底层细节的情况下开发。这样就可以轻松的完成海量数据的存储和计算。
### Hadoop的特性
* `高可靠：`采用冗余数据存储方式，这个即使一个副本发生故障，还有其它的副本保证正常对外服务。
* `高效：`采用了分布式存储和分布式处理两大核心，能够很高效的处理大量的数据。
* `高可扩展：`前面说了部署在廉价的计算机集群上，扩展起来很方便。
* `成本低：`参考高可扩展。
* `高容错：`参考高可靠，能够自动将失败任务重新分配。
* `平台：`运行在Linux上，基于java开发的hadoop跨平台优势可以很好完成。
* 支持多种语言编程

### Hadoop生态系统
hadoop除了HDFS和MapReduce外，还还包括了其它很多的功能组件。例如：经常听到的zookeeper、hbase、hive、pig、mahout、sqoop、flume、ambari等功能组件。
![hadoop生态系统](https://upload-images.jianshu.io/upload_images/14603910-d95009e2b8454ef4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

下面对各个组件做一个简单的概述，比较常用的着重描述。
* `Ambari：`一种基于web的工具，就作用来说，就是创建、管理、监视Hadoop生态圈的集群；就是为了让 Hadoop 以及相关的大数据软件更容易使用的一个工具。
![Ambari的Dashboard页面](https://upload-images.jianshu.io/upload_images/14603910-d75a616b1190248b.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

* `Zookeeper：`为分布式系统提供一致性协同服务，像配置服务、命名服务、分布式同步等，前面[服务发现](https://www.jianshu.com/p/8a4f7d579c58)这篇文章中也讲到了为什么Zookeeper不适合做发现服务，感兴趣的可以去了解下，还有[消息中间件](https://www.jianshu.com/p/23fe3ede4756)里面也讲到了Kafka使用Zookeeper来维护集群信息。
**下面讲讲Zookeeper特性**
    1. `最终一致性：`最重要的性能，client不论连接到哪个server，展示都是同一个视图。
    2. `可靠性：`具有简单、健壮、良好性能，如果消息被一台server接受，它将被所有server接受。
    3. `实时性：`保证client在一个时间间隔范围内获得server的更新信息/失效信息，但存在网络延时等原因，不能保证所有client同时得到，应该在读数据之前调用sync接口同步。
    4. `等待无关：`互不相关，慢的或者失效的client不得干涉快的client的请求。
    5. `原子性：`只有成功或者失败，没有中间状态。
    6. `顺序性：`从同一客户端发起的事务请求，都会最终被严格的按照其发送顺序被应用到zk中，包括全局有序和偏序两种，全局有序好理解，就是所有的server的发布消息顺序一样；偏序存在无法比较的现象，如果一个消息B在消息A后被同一个发布者发布，A必将排在B前面。
Zookeeper的核心是原子广播，这个机制保证了各个server之间的同步，leader崩溃，由server发起选举。
典型的应用场景(配置文件管理、集群管理、同步锁、leader选举、队列管理等)
**最典型集群模式： Master/Slave 模式（主备模式）**，Master负责写，Slave负责读，但Zookeeper没有使这种模式，采用了三种角色。
**Zookeeper中三种角色**
    * `领导者(leader)：`负责进行发起投票和决议，更新系统状态。
    * `学习者：`分为跟随着(follower)和观察者(observer)，前者用于接收客户请求并向客户端返回结果，参与投票；后者接收客户端写请求，转发给领导者，不参与投票，只同步领导者的状态。
    * `客户端：`请求发起方。
![zookeeper](https://upload-images.jianshu.io/upload_images/14603910-23e19492bfeb411a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

* `Hbase：`一个实时读写、分布式的列式数据库，主要是为了弥补Hadoop对实时操作的缺陷。和传统关系型数据库有一个很重要的区别是，一个是基于行，一个是基于列。可以说它是键值存储，也可以说它是多时间版本映射的数据库。
**四个描述**
    * `行键(rowkey)：`可以理解它为唯一ID，唯一标识，Hbase是不允许跨行的事务，所有rowkey和列族的设计就尤为重要和取巧。
    * `列族/列键(column family)：`一个表中必须至少有一个列族，列族是由多个列组成的，列族是能影响数据存储的物理特性。
    * `列限定符(column key)：`可以理解为列。列族里的数据是通过列限定符来定位。列限定符不需要事前定义，这也是和关系型数据库的区别，支持任意扩展。
    * `时间戳(timestamp)：`可以理解为行键、列族、列限定符组成了一个单元(cell),cell是有时间版本，用时间戳标识，默认是3个。

* `Hive：`sql转换MapReduce程序语言，可以减少MapReduce jobs编写工作，Hive提供了类似sql语言的查询语言-Hive QL,可以通过Hive QL语句快速实现简单的MapReduce统计，十分适合做数据仓库的统计分析。

* `Pig：`在MapReduce上创建了更简单的过程语言抽象，提供了一种更接近结构化查询语言(SQL)的接口，可以理解为Pig最大的作用就是对MapReduce算法(框架)实现了一套shell脚本 ，称之为：Pig Latin。

* `Mahout：`用于机器学习的一个框架，旨在帮助更方便快捷创建智能应用程序，包含许多实现，聚类、分类、推荐过滤、频繁子项挖掘等。

* `MapReduce：`一种离线计算框架，用于大规模数据集的平行运算，将并行计算过程高度抽象到了两个函数，Map和Reduce；这样就可以在不了解分布式系统底层细节的情况下进行平行应用开发，核心思想是：“分而治之”，把输入的数据集切分为若干独立的数据库，分发给各个分节点共同平行完成，最后聚合结果得到最终结果。

* `YARN：`调度系统，资源管理器，最初是为了修复MapReduce实现的不足，因为MapReduce是采用了Master/Slave 模式，一个JobTracker负责作业调度和资源管理，多个TaskTracker负责执行被指派的具体任务，所以会存在单点故障、任务过重、内存溢出、资源划分不合理等缺陷。

* `HDFS：`Hadoop分布式文件系统，是针对谷歌文件系统GFS的开源实现，具有处理超大数据、流式处理、可以运行在廉价商用服务器上等有点。

* `Flume：`分布式的海量日志采集，聚合和传输的系统，Flume具有高可用，分布式，配置工具，其设计的原理也是基于将数据流，如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。

* `Sqoop：`SQL-to-Hadoop的缩写，主要用来在Hadoop和关系数据库之间交换数据，通过Sqoop可以方便的将数据从关系数据库中导入Hadoop，或者将数据从Hadoop导出到关系数据库，Sqoop主要通过JDBC和关系数据库进行交互。

**附加几个其它的功能组件**
* `Storm：`Storm是Twitter开源的分布式实时大数据处理框架，流计算平台，优点是无延迟，缺点是不够灵活，想要统计的东西必须预知道；要达到更新实时，在数据流进来的时候就开始处理，比如广告点击计算，它的实时性要远远好于MapReduce计算框架。

* `Spark：`MapReduce计算框架不适合迭代计算和交互计算，MapReduce是一种磁盘计算框架，而Spark则是一种内存计算框架，它将数据尽可能放到内存中提高迭代应用和交互式应用的计算效率。

* `Pregel：`Pregel是Google提出的大规模分布式图计算平台，专门用来解决网页链接分析、社交数据挖掘等实际应用中涉及的大规模分布式图计算问题，Pregel作为分布式图计算的计算框架，主要用于图遍历、最短路径、PageRank计算等。

**针对Hadoop的改进和提升**
Hadoop框架自身的改进，从1.0到2.0

| 组件| Hadoop1.0的问题 | Hadoop2.0的改进 |
| :---: | :----: | :----: |
| HDFS | 单一名称节点，存在单点失效问题 | 设计了HDFS HA，提供名称节点热备份机制|
|    | 单一命名空间，无法实现资源隔离      | 设计了HDFS联邦，管理多个命名空间 |
|  MapReduce  | 资源管理效率底  | 设计了新的资源管理框架YARN |

不断完善的Hadoop生态系统

| 组件 | 功能 | 解决Hadoop中存在的问题 |
| :---: | :----: | :----: |
| Pig | 处理大规模数据的脚本语言，用户只要编写几条简单的语句，系统会自动转换为MapReduce作业 | 抽象层次低，需要手工编写大量代码 |
| Oozie   | 工作流和协作服务引擎，协调Hadoop上运行的不同任务 | 没有提供作业依赖关系管理机制，需要用户自己处理作业之间的依赖关系 |
|  Tez  | 支持DAG作业的计算框架，对作业的操作进行重新分解和组合，形成一个搭的DAG作业，减少不必要操作  | 不同的MapReduce任务之间存在重复操作，降低了效率 |
| Kafka | 分布式发布订阅消息系统，不同类型的分布式系统可以统一接入到Kafka，实现和Hadoop各个组件之间的不同类型数据的实时高效交换  | Hadoop生态系统中各个组件和其它产品之间缺乏统一的、高效的数据交换中介 |

### 结语  
这里主要是对Hadoop生态系统的一些功能组件做一个简单的归类描述，不涉及到具体的实现。
感兴趣的可以看看个别组件功能的详细实战。    
[浅谈Hbase与中间的一些设计策略](https://www.jianshu.com/u/299dd40d2451)  
[个人博客](https://ohcomeyes.github.io)~  
[简书](https://www.jianshu.com/u/299dd40d2451)~
